{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.utils.data as Data\n",
    "\n",
    "# 数据的导入\n",
    "with open(r'F:\\杂物\\5600\\output_data/lenth.csv', 'r') as f:\n",
    "    forcedata = f.readlines()\n",
    "# del forcedata[0]\n",
    "# print(forcedata[0])\n",
    "f.close()\n",
    "X_data = []\n",
    "y_data = []\n",
    "channel_1 = []\n",
    "channel_2 = []\n",
    "channel1_data=[]\n",
    "channel2_data=[]\n",
    "for num, item in enumerate(forcedata):\n",
    "    if num == 0:\n",
    "        continue\n",
    "    data = item.split(',')\n",
    "    force = data[-2].replace('\\n', '')\n",
    "    del data[-2]\n",
    "    channel_1.append(data[0])\n",
    "    channel_2.append(data[1].strip('\\n'))\n",
    "    if len(channel_1) == 90:\n",
    "        channel1_data.append(channel_1)\n",
    "        channel2_data.append(channel_2)\n",
    "        y_data.append(force)\n",
    "        channel_1 = []\n",
    "        channel_2 = []\n",
    "f.close()\n",
    "# print(len(channel1_data))\n",
    "# print(channel1_data[0])\n",
    "# print(len(channel1_data[0]))\n",
    "# print(len(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.clear()\n",
    "scale = StandardScaler()\n",
    "lenth_s=scale.fit_transform(channel1_data)\n",
    "strain_s=scale.fit_transform(channel2_data)\n",
    "\n",
    "\n",
    "for i in range(0,len(lenth_s)):\n",
    "    data1=np.hstack((lenth_s[i],strain_s[i]))\n",
    "    X_data.append(data1.reshape(1,2,90))\n",
    "# print(len(X_data))\n",
    "# print(X_data[0].shape)\n",
    "# print(type(X_data[0]))\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "shuffle = np.random.permutation(len(X_data))\n",
    "train_num = int(len(shuffle) * 0.9)\n",
    "for i in shuffle[train_num:]:\n",
    "    X_test.append(X_data[i])\n",
    "    y_test.append(y_data[i])\n",
    "for i in shuffle[:train_num]:\n",
    "    X_train.append(X_data[i])\n",
    "    y_train.append(y_data[i])\n",
    "\n",
    "# print(type(X_train))\n",
    "# print(len(X_train))\n",
    "# print(type(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ch\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x = np.stack(((X_train[j].reshape(2, 1, -1) for j in range(0, len(X_train)))), axis=0)\n",
    "test_x = np.stack(((X_test[j].reshape(2, 1, -1) for j in range(0, len(X_test)))), axis=0)\n",
    "# train_xt = torch.from_numpy(X_train.astype(np.float32))\n",
    "\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "train_xt = torch.from_numpy(train_x.astype(np.float32))\n",
    "train_yt = torch.from_numpy(y_train.astype(np.float32))\n",
    "test_xt = torch.from_numpy(test_x.astype(np.float32))\n",
    "# print(train_xt.shape)\n",
    "# test_yt = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "\n",
    "train_data = Data.TensorDataset(train_xt, train_yt)\n",
    "# test_data = Data.TensorDataset(test_xt, test_yt)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
